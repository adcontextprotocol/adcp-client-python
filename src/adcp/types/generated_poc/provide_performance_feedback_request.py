# generated by datamodel-codegen:
#   filename:  provide-performance-feedback-request.json
#   timestamp: 2025-11-21T15:57:17+00:00

from __future__ import annotations

from typing import Annotated, Any

from adcp.types.base import AdCPBaseModel
from pydantic import AwareDatetime, ConfigDict, Field, RootModel

from . import feedback_source as feedback_source_1
from . import metric_type as metric_type_1


class MeasurementPeriod(AdCPBaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    end: Annotated[
        AwareDatetime, Field(description='ISO 8601 end timestamp for measurement period')
    ]
    start: Annotated[
        AwareDatetime, Field(description='ISO 8601 start timestamp for measurement period')
    ]


class ProvidePerformanceFeedbackRequest1(AdCPBaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    buyer_ref: Annotated[
        str | None, Field(description="Buyer's reference for the media buy", min_length=1)
    ] = None
    context: Annotated[
        dict[str, Any] | None,
        Field(
            description='Initiator-provided context included in the request payload. Agentsmust echo this value back unchanged in responses and webhooks. Use for UI/session hints, correlation tokens, or tracking metadata.'
        ),
    ] = None
    creative_id: Annotated[
        str | None,
        Field(
            description='Specific creative asset (if feedback is creative-specific)', min_length=1
        ),
    ] = None
    feedback_source: Annotated[
        feedback_source_1.FeedbackSource | None, Field(description='Source of the performance data')
    ] = feedback_source_1.FeedbackSource.buyer_attribution
    measurement_period: Annotated[
        MeasurementPeriod, Field(description='Time period for performance measurement')
    ]
    media_buy_id: Annotated[
        str, Field(description="Publisher's media buy identifier", min_length=1)
    ]
    metric_type: Annotated[
        metric_type_1.MetricType | None, Field(description='The business metric being measured')
    ] = metric_type_1.MetricType.overall_performance
    package_id: Annotated[
        str | None,
        Field(
            description='Specific package within the media buy (if feedback is package-specific)',
            min_length=1,
        ),
    ] = None
    performance_index: Annotated[
        float,
        Field(
            description='Normalized performance score (0.0 = no value, 1.0 = expected, >1.0 = above expected)',
            ge=0.0,
        ),
    ]


class ProvidePerformanceFeedbackRequest2(AdCPBaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    buyer_ref: Annotated[
        str, Field(description="Buyer's reference for the media buy", min_length=1)
    ]
    context: Annotated[
        dict[str, Any] | None,
        Field(
            description='Initiator-provided context included in the request payload. Agentsmust echo this value back unchanged in responses and webhooks. Use for UI/session hints, correlation tokens, or tracking metadata.'
        ),
    ] = None
    creative_id: Annotated[
        str | None,
        Field(
            description='Specific creative asset (if feedback is creative-specific)', min_length=1
        ),
    ] = None
    feedback_source: Annotated[
        feedback_source_1.FeedbackSource | None, Field(description='Source of the performance data')
    ] = feedback_source_1.FeedbackSource.buyer_attribution
    measurement_period: Annotated[
        MeasurementPeriod, Field(description='Time period for performance measurement')
    ]
    media_buy_id: Annotated[
        str | None, Field(description="Publisher's media buy identifier", min_length=1)
    ] = None
    metric_type: Annotated[
        metric_type_1.MetricType | None, Field(description='The business metric being measured')
    ] = metric_type_1.MetricType.overall_performance
    package_id: Annotated[
        str | None,
        Field(
            description='Specific package within the media buy (if feedback is package-specific)',
            min_length=1,
        ),
    ] = None
    performance_index: Annotated[
        float,
        Field(
            description='Normalized performance score (0.0 = no value, 1.0 = expected, >1.0 = above expected)',
            ge=0.0,
        ),
    ]


class ProvidePerformanceFeedbackRequest(
    RootModel[ProvidePerformanceFeedbackRequest1 | ProvidePerformanceFeedbackRequest2]
):
    root: Annotated[
        ProvidePerformanceFeedbackRequest1 | ProvidePerformanceFeedbackRequest2,
        Field(
            description='Request payload for provide_performance_feedback task',
            title='Provide Performance Feedback Request',
        ),
    ]
