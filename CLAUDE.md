# Python SDK Development Learnings

## Type Safety & Code Generation

**Auto-generate from specs when possible**
- Download schemas from canonical source (e.g., adcontextprotocol.org/schemas)
- Generate Pydantic models automatically - keeps types in sync with spec
- Validate generated code in CI (syntax check + import test)
- For missing upstream types, add type aliases with clear comments explaining why

**Handling Missing Schema Types**
When schemas reference types that don't exist upstream:
```python
# MISSING SCHEMA TYPES (referenced but not provided by upstream)
# These types are referenced in schemas but don't have schema files
FormatId = str
PackageRequest = dict[str, Any]
```

**NEVER Modify Generated Files Directly**

Files in `src/adcp/types/generated_poc/` and `src/adcp/types/generated.py` are auto-generated by `scripts/generate_types.py`. Any manual edits will be lost on regeneration.

**CRITICAL**: Do not add code to `generated.py` or any files in `generated_poc/` directory. These are regenerated from schemas.

**Post-Generation Fix System:**

We use `scripts/post_generate_fixes.py` which runs automatically after type generation to apply necessary modifications that can't be generated.

**Type Name Collisions:**

The upstream AdCP schemas define multiple types with the same name (e.g., `Contact`, `Asset`, `Status`) in different schema files. These are **genuinely different types** with different fields, not duplicates.

When consolidating exports in `generated.py`, we use a "first wins" strategy (alphabetical by module name) and warn about collisions. Users can still access all versions via module-qualified imports:

```python
# Access the "winning" version
from adcp.types.generated import Asset

# Access specific versions
from adcp.types.generated_poc.brand_manifest import Asset as BrandAsset
from adcp.types.generated_poc.format import Asset as FormatAsset
```

**Upstream Issue:** This should ideally be fixed in the AdCP schema definitions by either:
- Using unique names (e.g., `BrandAsset` vs `FormatAsset`)
- Sharing common types via `$ref`
- Using discriminated unions where appropriate

**Current fixes applied:**
1. **Model validators** - Injects `@model_validator` decorators into:
   - `PublisherProperty.validate_mutual_exclusivity()` - enforces property_ids/property_tags mutual exclusivity
   - `Product.validate_publisher_properties_items()` - validates all publisher_properties items

2. **Self-referential types** - Fixes `preview_render.py` if it contains module-qualified self-references

3. **Forward references** - Fixes BrandManifest imports in:
   - `promoted_offerings.py`
   - `create_media_buy_request.py`
   - `get_products_request.py`

**To add new post-generation fixes:**
Edit `scripts/post_generate_fixes.py` and add a new function. The script:
- Runs automatically via `generate_types.py`
- Is idempotent (safe to run multiple times)
- Validates fixes were successfully applied
- Fails loudly if schema changes break the fix patterns

## Semantic Type Aliases for Discriminated Unions

**Problem**: The code generator (`datamodel-code-generator`) creates numbered type names for discriminated union variants (e.g., `PreviewRender1`, `PreviewRender2`, `SubAsset1`, `SubAsset2`). While functionally correct, these don't convey semantic meaning.

**Solution**: Add semantic type aliases in `src/adcp/types/aliases.py` that provide clear, descriptive names based on the discriminator field value.

**Process for Adding New Semantic Aliases:**

1. **Identify the discriminated union types** - Look for numbered types (e.g., `TypeName1`, `TypeName2`) in generated files
2. **Determine the discriminator field** - Check the schema/generated code for the `Literal` field that distinguishes variants
3. **Create semantic aliases in `aliases.py`**:
   ```python
   # Import the generated types
   from adcp.types.generated import PreviewRender1, PreviewRender2, PreviewRender3

   # Create semantic aliases based on discriminator values
   UrlPreviewRender = PreviewRender1  # output_format='url'
   HtmlPreviewRender = PreviewRender2  # output_format='html'
   BothPreviewRender = PreviewRender3  # output_format='both'
   ```

4. **Add to exports** in `aliases.py`:
   ```python
   __all__ = [
       ...,
       "UrlPreviewRender",
       "HtmlPreviewRender",
       "BothPreviewRender",
   ]
   ```

5. **Re-export from main package** in `src/adcp/__init__.py`:
   ```python
   from adcp.types.aliases import (
       ...,
       UrlPreviewRender,
       HtmlPreviewRender,
       BothPreviewRender,
   )

   __all__ = [
       ...,
       "UrlPreviewRender",
       "HtmlPreviewRender",
       "BothPreviewRender",
   ]
   ```

6. **Add comprehensive tests** in `tests/test_type_aliases.py`:
   - Test that aliases can be imported
   - Test that aliases point to correct generated types
   - Test that aliases are exported from main package

**Current Semantic Aliases:**

- **Preview Renders** (discriminated by `output_format`):
  - `UrlPreviewRender` = `PreviewRender1` (output_format='url')
  - `HtmlPreviewRender` = `PreviewRender2` (output_format='html')
  - `BothPreviewRender` = `PreviewRender3` (output_format='both')

- **VAST Assets** (discriminated by `delivery_type`):
  - `UrlVastAsset` = `VastAsset1` (delivery_type='url')
  - `InlineVastAsset` = `VastAsset2` (delivery_type='inline')

- **DAAST Assets** (discriminated by `delivery_type`):
  - `UrlDaastAsset` = `DaastAsset1` (delivery_type='url')
  - `InlineDaastAsset` = `DaastAsset2` (delivery_type='inline')

- **SubAssets** (discriminated by `asset_kind`):
  - `MediaSubAsset` = `SubAsset1` (asset_kind='media')
  - `TextSubAsset` = `SubAsset2` (asset_kind='text')

- **Response Types** (discriminated by success/error):
  - Success/Error variants for: ActivateSignal, BuildCreative, CreateMediaBuy, ProvidePerformanceFeedback, SyncCreatives, UpdateMediaBuy

- **Request Types** (discriminated by operation variant):
  - `PreviewCreativeFormatRequest`/`PreviewCreativeManifestRequest`
  - `UpdateMediaBuyPackagesRequest`/`UpdateMediaBuyPropertiesRequest`

- **Activation Keys** (discriminated by identifier type):
  - `PropertyIdActivationKey`/`PropertyTagActivationKey`

**Guidelines for Choosing What to Alias:**

✅ **DO create aliases for:**
- User-facing discriminated unions used in API calls
- Types where the discriminator conveys important semantic meaning
- Types where numbered suffixes cause confusion

❌ **DON'T create aliases for:**
- Internal helper types not commonly used directly
- Types where parent context makes the meaning clear
- Generic helper types (Input1, Parameters2, etc.)

**Type Checking Best Practices**
- Use `TYPE_CHECKING` for optional dependencies to avoid runtime import errors
- Use `cast()` for JSON deserialization to satisfy mypy's `no-any-return` checks
- Add specific `type: ignore` comments (e.g., `# type: ignore[no-any-return]`) rather than blanket ignores
- Test type checking in CI across multiple Python versions (3.10+)

## Testing Strategy

**Mock at the Right Level**
- For HTTP clients: Mock `_get_client()` method, not the httpx class directly
- For async operations: Use `AsyncMock` for async functions, `MagicMock` for sync methods
- Remember: httpx's `response.json()` is SYNCHRONOUS, not async

**Test API Changes Properly**
- When API changes from kwargs to typed objects, update tests to match
- Remove tests for non-existent methods rather than keep failing tests
- Test the API as it exists, not as we wish it existed

## CI/CD & Release Automation

**GitHub Actions Secrets**
- Secret names matter! Check actual secret name in repository settings
- Common pattern: `PYPY_API_TOKEN` (not `PYPI_API_TOKEN`) for PyPI publishing
- Test locally with `python -m build` before relying on CI

**Release Please Workflow**
- Runs automatically on push to main
- Creates release PR with version bump and changelog
- When release PR is merged, automatically publishes to PyPI
- Requires proper `[project.scripts]` entry point in pyproject.toml for CLI tools

**Entry Points for CLI Tools**
```toml
[project.scripts]
toolname = "package.__main__:main"
```
This enables `uvx toolname` and `pip install toolname` to work correctly.

## Python-Specific Patterns

**Optional Dependencies with TYPE_CHECKING**
```python
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from optional_lib import SomeType

try:
    from optional_lib import SomeType as _SomeType
    AVAILABLE = True
except ImportError:
    AVAILABLE = False
```

**Atomic File Operations**
For config files with sensitive data:
```python
temp_file = CONFIG_FILE.with_suffix(".tmp")
with open(temp_file, "w") as f:
    json.dump(config, f, indent=2)
temp_file.replace(CONFIG_FILE)  # Atomic rename
```

**Connection Pooling**
```python
# Reuse HTTP client across requests
self._client: httpx.AsyncClient | None = None

async def _get_client(self) -> httpx.AsyncClient:
    if self._client is None:
        limits = httpx.Limits(
            max_keepalive_connections=10,
            max_connections=20,
        )
        self._client = httpx.AsyncClient(limits=limits)
    return self._client
```

**Format Definition Caching (Production Consideration)**

Creative formats rarely change, so production implementations should cache format definitions to avoid redundant `list_creative_formats` calls:

```python
from functools import lru_cache

# Option 1: Simple LRU cache for format lookups
@lru_cache(maxsize=100)
async def get_format_definition(agent_url: str, format_id: str) -> Format:
    """Cached format definition lookup."""
    agent = get_agent_for_url(agent_url)
    result = await agent.list_creative_formats()
    for fmt in result.data.formats:
        if fmt.format_id.id == format_id:
            return fmt
    raise ValueError(f"Format not found: {format_id}")

# Option 2: TTL-based cache with periodic refresh
class FormatCache:
    def __init__(self, ttl_seconds: int = 3600):
        self._cache: dict[tuple[str, str], tuple[Format, float]] = {}
        self._ttl = ttl_seconds

    async def get_format(self, agent_url: str, format_id: str) -> Format:
        """Get format with TTL-based caching."""
        key = (agent_url, format_id)
        if key in self._cache:
            fmt, timestamp = self._cache[key]
            if time.time() - timestamp < self._ttl:
                return fmt

        # Cache miss or expired - fetch fresh
        fmt = await self._fetch_format(agent_url, format_id)
        self._cache[key] = (fmt, time.time())
        return fmt
```

**Cache Invalidation Strategies:**
1. **TTL-based** (recommended): Formats rarely change, 1-hour TTL is reasonable
2. **Version-based**: Use format version in ID (e.g., `banner_300x250_v2`)
3. **ETags**: Check `Last-Modified` headers if agents support it
4. **Explicit invalidation**: Clear cache when format changes detected

## Common Pitfalls to Avoid

**String Escaping in Code Generation**
Always escape in this order:
1. Backslashes first: `\\` → `\\\\`
2. Then quotes: `"` → `\"`
3. Then control chars (newlines, tabs)

Wrong order creates invalid escape sequences!

**Python Version Requirements**
- Union syntax `str | None` requires Python 3.10+
- Always include `from __future__ import annotations` at top of files
- Use `target-version = "py310"` in ruff/black config
- Test in CI across all supported Python versions

**Test Fixtures vs. Mocks**
- Don't over-mock - it hides serialization bugs
- Test actual API calls when possible
- Use real Pydantic validation in tests
- Mock external services, not internal logic

## Additional Important Reminders

**NEVER**:
- Assume a "typo" without checking the actual secret name in GitHub settings

**ALWAYS**:
- Verify secret names match repository settings before "fixing" them
